// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-about.adoc

[id="nodes-pods-autoscaling-creating-memory_{context}"]

= Creating a horizontal pod autoscaler object for memory utilization

You can create a horizontal pod autoscaler to automatically scale pods in a Deployment when memory usage exceeds a specified limit.

[IMPORTANT]
====
Autoscaling for memory utilization is a Technology Preview feature only.
ifdef::openshift-enterprise,openshift-webscale[]
Technology Preview features are not supported with Red Hat production service
level agreements (SLAs), might not be functionally complete, and Red Hat does
not recommend to use them for production. These features provide early access to
upcoming product features, enabling customers to test functionality and provide
feedback during the development process.

For more information on Red Hat Technology Preview features support scope, see
https://access.redhat.com/support/offerings/techpreview/.
endif::[]
====

.Prerequisites

In order to use horizontal pod autoscalers, your cluster administrator must have properly configured cluster metrics.
You can use the `oc describe PodMetrics <pod-name>` command to determine if metrics are configured. If metrics are
configured, the output appears similar to the following, with `Cpu` and `Memory` displayed under `Usage`.

----
$ oc describe PodMetrics openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
----

[source,yaml,options="nowrap"]
----
Name:         openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Namespace:    openshift-kube-scheduler
Labels:       <none>
Annotations:  <none>
API Version:  metrics.k8s.io/v1beta1
Containers:
  Name:  wait-for-host-port
  Usage:
    Memory:  0
  Name:      scheduler
  Usage:
    Cpu:     8m
    Memory:  45440Ki
Kind:        PodMetrics
Metadata:
  Creation Timestamp:  2019-05-23T18:47:56Z
  Self Link:           /apis/metrics.k8s.io/v1beta1/namespaces/openshift-kube-scheduler/pods/openshift-kube-scheduler-ip-10-0-135-131.ec2.internal
Timestamp:             2019-05-23T18:47:56Z
Window:                1m0s
Events:                <none>
----

.Procedure

To create a horizontal pod autoscaler for memory utilization:

. Create a YAML file that contains one of the following:
+
.Sample HPA object for an absolute value
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: memory-autoscale <1>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1 <2>
    name: example <3>
    kind: DeploymentConfig <4>
  minReplicas: 1 <5>
  maxReplicas: 10 <6>
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        name: memory-absolute
        targetAverageValue: 500Mi <7>
----
<1> Specify the name of this horizontal pod autoscaler object.
<2> Specify `apps/v1` as the API version of the object to scale.
<3> Specify the name of the object to scale.
<4> Specify the kind of object to scale.
<5> Specify the minimum number of replicas when scaling down.
<6> Specify the maximum number of replicas when scaling up.
<7> Specify the average amount of memory used per pod.

.Sample HPA object for a percentage
[source,yaml,options="nowrap"]
----
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: memory-autoscale <1>
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1 <2>
    name: example <3>
    kind: DeploymentConfig <4>
  minReplicas: 1 <5>
  maxReplicas: 10 <6>
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        name: memory-percent
        type: Utilization
        averageUtilization: 50 <7>
----
<1> Specify the name of this horizontal pod autoscaler object.
<2> Specify `apps/v1` as the API version of the object to scale.
<3> Specify the name of the object to scale.
<4> Specify the kind of object to scale.
<5> Specify the minimum number of replicas when scaling down.
<6> Specify the maximum number of replicas when scaling up.
<7> The average percentage of the requested memory that each pod should be using.

. Create the autoscaler from the above file:
+
----
$ oc create -f <file-name>.yaml
----
+
For example:
+
----
$ oc create -f hpa.yaml

horizontalpodautoscaler.autoscaling/hpa-resource-metrics-memory created
----

. Verify that the HPA was created:
+
----
$ oc get hpa memory-autoscale

NAME               REFERENCE                  TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
memory-autoscale   DeploymentConfig/example   <unknown>/500Mi   1         10        0          56s
----
+
----
$ oc describe hpa memory-autoscale

Name:                                                  memory-autoscale
Namespace:                                             default
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Wed, 22 May 2019 20:56:35 -0400
Reference:                                             DeploymentConfig/example
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  <unknown>/500Mi
Min replicas:                                          1
Max replicas:                                          10
DeploymentConfig pods:                                 0 current / 0 desired
Events:                                                <none>
----
